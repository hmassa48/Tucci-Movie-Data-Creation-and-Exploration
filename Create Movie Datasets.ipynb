{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape for Movie Data Set \n",
    "\n",
    "This notebook is part of my Stanley Tucci move exploration project. In this notebook, I will be providing the process of scraping the data we want from Wikipedia. This data will later be further cleaned and analyzed in subsequent notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Base URLs for Actor/Movie Genre/Production Company We Want\n",
    "\n",
    "Change what URL you want to explore for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_wiki_page = 'https://en.wikipedia.org/wiki/Stanley_Tucci'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Wiki Page with Beautiful Soup and Select Film Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(main_wiki_page)\n",
    "\n",
    "#Convert to beautiful soup object\n",
    "soup = bs(r.content)\n",
    "\n",
    "#print html\n",
    "contents = soup.prettify()\n",
    "#print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded in this wikipedia page, we want to choose the URLs of the movies/TV shows we want to explore. In this example, I am only going to explore the Films that Stanley Tucci acted in; however, there is a possibility for expansion to include his many TV (an emmy winning) performances in a later iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get only the Film Table from the HTML Page\n",
    "\n",
    "table = soup.find_all('table', class_=\"wikitable\")[0]   # Only use the first table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this table, I am only going to select films that have a wikipedia page. The films without a Wikipedia page could be explored in another iteration of the project and would require more independent research on each film. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only the Links are italicized, select the links of his movies\n",
    "movies = table.select(\"i a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Information Table For Each Film "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section selects information about each of the films. This section also includes the following cleaning: \n",
    "\n",
    "1. Remove all references [1]\n",
    "2. Make Long Strings into Lists (production team, starring etc) \n",
    "3. Change the numerical strings to integer values\n",
    "4. Make movie release a date time object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple String Replacement \\xa0 becomes a space\n",
    "def get_content_value(row_data):\n",
    "    if row_data.find('li'):\n",
    "        return [li.get_text(\" \", strip = True).replace(\"\\xa0\" , \" \" )for li in row_data.find_all('li')]\n",
    "    else:\n",
    "        return row_data.get_text(\" \", strip = True).replace(\"\\xa0\" , \" \" )\n",
    "\n",
    "## Create a Function to Take in a URL \n",
    "def get_info_box(url):\n",
    "    #get just the info box of the movie\n",
    "\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    #Convert to beautiful soup object\n",
    "    soup = bs(r.content)\n",
    "    \n",
    "    #Print out the HTML \n",
    "    contents = soup.prettify()\n",
    "    \n",
    "    info_box = soup.find(class_='infobox vevent')\n",
    "    info_rows = info_box.find_all('tr')\n",
    "    \n",
    "    \n",
    "    movie_info = {}\n",
    "\n",
    "    for index, row in enumerate(info_rows):\n",
    "        if index == 0:\n",
    "            movie_info['title'] = row.find('th').get_text(\" \", strip = True)\n",
    "        elif index ==1:\n",
    "            continue \n",
    "        else:\n",
    "            content_key = row.find('th').get_text(\" \", strip = True)\n",
    "            content_value = get_content_value(row.find('td'))\n",
    "            movie_info[content_key] = content_value\n",
    "            \n",
    "    return movie_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show this works and show one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': \"Prizzi's Honor\",\n",
       " 'Directed by': 'John Huston',\n",
       " 'Produced by': 'John Foreman',\n",
       " 'Screenplay by': 'Richard Condon Janet Roach',\n",
       " 'Based on': \"Prizzi's Honor by Richard Condon\",\n",
       " 'Starring': ['Jack Nicholson', 'Kathleen Turner'],\n",
       " 'Music by': 'Alex North',\n",
       " 'Cinematography': 'Andrzej Bartkowiak',\n",
       " 'Edited by': 'Kaja Fehr Rudi Fehr',\n",
       " 'Production company': 'ABC Motion Pictures',\n",
       " 'Distributed by': '20th Century Fox (U.S.) Producers Sales Organization (International)',\n",
       " 'Release date': 'June 14, 1985',\n",
       " 'Running time': '130 minutes',\n",
       " 'Country': 'United States',\n",
       " 'Language': 'English',\n",
       " 'Budget': '$16 million [1]',\n",
       " 'Box office': '$26.6 million [2]'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_info_box(base_path + movies[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monkey Shines\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "\n",
      "A Modern Affair\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "\n",
      "The Life and Death of Peter Sellers\n",
      "'NoneType' object has no attribute 'find'\n",
      "\n",
      "The Wind Rises\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_info_list = []\n",
    "base_path = 'https://en.wikipedia.org/'\n",
    "for index, movie in enumerate(movies) :\n",
    "    try:\n",
    "        relative_path = movie['href']\n",
    "        full_path = base_path + relative_path\n",
    "        title = movie['title']\n",
    "        \n",
    "        movie_info_list.append(get_info_box(full_path))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(movie.get_text())\n",
    "        print(e)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Iteration:\n",
    "These will not be assessed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Plot Overview For Each Film"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For finding the plot, I am going to use a different setup and use the Wikipedia package in python. \n",
    "\n",
    "Cleaning done in this section:\n",
    "\n",
    "1. List sections named Plot or Synopsis, if one of those doesn't exist just take the first introductory paragraph\n",
    "2. Remove all \\n and \\' values in the plot, while keeping all other punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_plot_text = {}\n",
    "\n",
    "def get_plot_text(movie_list):\n",
    "    import wikipedia\n",
    "    \n",
    "    #get title of wikipedia page interested in\n",
    "    for index, movie in enumerate(movie_list):\n",
    "        try:\n",
    "            wiki = wikipedia.page(movie['title'])\n",
    "            \n",
    "            #extract plain text \n",
    "            text = wiki.content\n",
    "            \n",
    "            # Replace '==' with '' (an empty string)\n",
    "            text = text.replace('==', '')\n",
    "            \n",
    "            #Get Sections of the Wikipedia page\n",
    "            split_text = text.split('\\n\\n\\n')\n",
    "            \n",
    "            #Get Sections of the Wikipedia page\n",
    "            plot = split_text[1]\n",
    "            \n",
    "            #Clean up Plot Text \n",
    "            \n",
    "            for index, text in enumerate(split_text):\n",
    "                if 'Plot' in text[:5] :\n",
    "                    plot = text[6:]\n",
    "                    break\n",
    "                \n",
    "                if 'Synopsis' in text[:10]:\n",
    "                    plot = text[10:]\n",
    "                    break\n",
    "                    \n",
    "                if index == len(split_text) - 1:\n",
    "                    plot = split_text[0]\n",
    "            \n",
    "            \n",
    "            # Replace '\\n' (a new line) with '' & end the string at $1000.\n",
    "            plot = plot.replace('\\n', '')\n",
    "            plot = plot.replace('\\'','')\n",
    "            \n",
    "              \n",
    "            #Finish cleaning of plot and return in the dictionary\n",
    "            movie_plot_text[movie['title']] = plot\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(movie.get_text())\n",
    "            print(e)\n",
    "            print()\n",
    "            \n",
    "    return movie_plot_text\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julie & Julia\n",
      "Page id \"julien julian\" does not match any pages. Try another id!\n",
      "\n",
      "The Silence\n",
      "Page id \"the silence (2013 film)\" does not match any pages. Try another id!\n",
      "\n",
      "The Witches\n",
      "Page id \"the witches 2021 film\" does not match any pages. Try another id!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot_text_dict = get_plot_text(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three movies that do not have a the title corresponding to their wikipedia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DataSets as a JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def save_data(title,data):\n",
    "    with open(title, 'w', encoding = 'utf-8') as f:\n",
    "        json.dump(data,f,ensure_ascii = False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def load_data(title):\n",
    "    with open(title,encoding = 'utf-8') as f:\n",
    "        return json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
